* An Invitation to Algorithms with Scheme            -*- Outline -*-

by Rich Loveland
r@rmloveland.com


* Preface

There are many books about algorithms.  Most provide detailed analyses
of topics such as ``big O notation'' and are aimed at an academic
audience.  As a result, they strive to be comprehensive, and in so
doing, run to hundreds of pages in length.

This book is different, because its goals are different.  First, it is
an *invitation* to algorithms; this means that we will cover one or
two of the most common algorithms in each of the standard areas such
as searching, sorting, trees, graphs, &c.

Second, it is an invitation to algorithms *with Scheme*.  This means
that we will use Scheme to describe the algorithms we want the
computer to perform.  As we will discover, this allows us to describe
our algorithms in a language that is often very similar to the
mathematical descriptions of those algorithms.  Whether this should be
seen as a strength or a weakness of the Scheme language is left for
the reader to decide.


* Prerequisites

This book does not try to teach the Scheme language.  We assume the
reader has already encountered an introduction to Scheme elsewhere.
In particular, you should be pretty comfortable with recursion.  A
good book that serves this purpose is _The Little Schemer_, by Dan
Friedman & Matthias Felleisen.  For a more detailed introduction to
the language, see Dybvig's excellent _The Scheme Programming
Language_.  Finally, although our implementation of choice for this
book is MIT/GNU Scheme, the code is mostly R5RS Scheme.  Where it
isn't R5RS because we use implementation-specific features, it will be
clearly noted.


* Conventions

MERGE vs %MERGE

???

* 00 - Introduction

Overview of the chapters.

The three (or so) big ideas of this book:

1. Divide and conquer
2. Recursion
3. ???

Testing library.

Utilities library.

Discussion of type annotations and return values in procedure
definitions -- practical, not academic. Facilitates skim-reading code.

Building a tags file for source navigation.

Edwin basics.

The `pp' procedure.

The `show-parameter-list' procedure (M-Shift-A).

The `scheme-complete-variable' procedure (ESC-TAB).

The debugger.


* 01 - Searching

NOTE: This should be chapter two, and `Sorting' should be first.

Binary search.

TODO: Rewrite `make-list-of-words-matching' to use the built-in
`re-string-match' procedure.


* 02 - Sorting

Although ostensibly, computers gonna compute, it turns out that most
of the time we use them for their data-shuffling capabilities more
than as calculators.  A lot of what we do with computers (some would
argue almost all of it) has to do with shuffling data around from one
place to the next (or one format into the next).  As a result,
computers are beginning to become external brains that we dump things
into for later use.

As external brains, one of the most important things computers help us
with is in finding things.  As it happens, it's much easier to search
for and find things if you put them in order first.  This is as true
for computers as it is for your house.

Hence, sorting.

In this chapter we will look at several implementations of merge sort,
starting with the naive tree-recursive version you can easily find on
the internet, and finishing up with a relatively performant iterative
implementation.  Why merge sort?  It has a few qualities that make it
worth using: first, it performs reasonably well; second, it is a good
example of the `divide and conquer' strategy for designing algorithms;
third, it suits Scheme well due to the way lists (cons cells, really)
are implemented.

If you can understand the implementation of merge sort described in
this chapter, you should have no problem learning more about (and
implementing your own versions of) quicksort, heap sort, and the like.


** Architecture of a Merge Sort Implementation

Merge sort is usually implemented with an architecture that consists
of two parts:

1. MERGE, a lower-level procedure which handles splicing two sublists
   together in an ordering determined by a predicate such as < or
   STRING<?.  Here is its expected output:

   ; MERGE : Pred List List -> List
   (rml/merge < '(2 191) '(18 45))
   ;Value 76: (2 18 45 191)

2. MERGE-SORT, a top-level procedure that calls MERGE repeatedly to
   splice successively larger lists together into sorted order.  In
   other words, it sorts a list (of numbers, in this case).

   ; MERGE-SORT : List Pred -> List
   (merge-sort '(17 51 55 13 12 75 98 48 98 89 68 86 89 51 73 18 92)
   ;Value 80: (12 13 17 18 48 51 51 55 68 73 75 86 89 89 92 98 98)


** How MERGE Works

Before we can do a merge sort, we need to write the MERGE procedure.
Remember that it splices two lists together in an ordering determined
by a predicate such as <.  (For our purposes, we will stick to numbers
for the rest of this implementation.)

An easy way to do this is to walk two lists, A and B, comparing each
pair of list elements in turn.  We will keep another list, RESULT,
where we will put our, er, result.  If A:X (the current element from A) is
less than B:X (the one from B), we push A:X onto the result list.
Otherwise, we push B:X on.

IMAGE

Finally, having traversed both of our input lists A and B, and
processed all the elements of each, we return RESULT.

IMAGE

It's important to note that RESULT is *not* a sorted list.  It has
been put into `pairwise order'.  This is a fancy way of saying that we
only compared two elements at a time, one each from A and B, as we
were building it.

At this point, you can probably begin to see why MERGE-SORT calls
MERGE over and over when it's sorting a list.


** Implementing MERGE

Let's begin implementing MERGE by reminding ourselves of its
specification.  MERGE takes as its arguments a predicate and two
lists, and it returns a `pairwise ordered' list.  Another way of
writing this is as follows (you may have noticed this notation above):

   ; MERGE : Pred List List -> List

This is just a way of annotating our program code that serves as a
form of documentation.  It makes it a little easier to remember what a
procedure does when you've been away from it for a while.  Given this
spec, we can start our implementation:

   ; MERGE : Pred List List -> List
   (define (merge pred A B)
     (let ((return '()))
       return))

This meets the spec, in that it takes the right arguments and returns
a list, but it doesn't actually do anything.  In fact, because we
already know we're going to be returning a list, let's write it in a
recursive style that uses an explicit list argument.  This explicit
list will be the value of RETURN we talked about earlier.  It also
means we need to update our spec slightly.

   ; MERGE : Pred List List List -> List
   (define (merge pred A B RETURN)
     RETURN)

Based on our above descriptions of the algorithm, the implementation
of MERGE is straightforward:

   (define (merge pred left right result)
     (cond ((and (null? left)
                 (null? right))
            (reverse result))
           ((and (not (null? left))
                 (not (null? right)))
            (if (pred (car left)
                      (car right))
                (merge-aux pred
                           (cdr left)
                           right
                           (cons (car left) result))
                (merge-aux pred
                           left
                           (cdr right)
                           (cons (car right) result))))
           ((not (null? left))
            (merge-aux pred (cdr left) right (cons (car left) result)))
           ((not (null? right))
            (merge-aux pred left (cdr right) (cons (car right) result)))
           (else #f)))

Let's go through the COND clause-by-clause.  First, as our recursive
base case, 

IMPL: Recursive merge sort.

IMPL: Bottom-up merge sort.

* 03 - Trees

Binary trees.

CSRMs: constructors, selectors, recognizers, and mutators.

Basic operations

- creation
- insertion
- updating (destructive/in-place)
- deletion

Walking the tree using higher order functions (see notes from ADuni lectures).

Sorting with treesort.

This is only fast if the tree is balanced, so give the ``slow
version'' first, since balanced trees are not introduced yet. Explain
why it can be slow.

Balanced binary trees.

Red-black tree or AVL tree? AVL is supposedly simpler to implement but
red-black is said to have superior tree rotation runtime -- once we
have a self-balancing tree of either type we can write the ``fast''
treesort!

* 04 - Graphs

Introduction to graphs.

How to represent graphs with another data structure -- matrix or hash
table. We might want to implement our own hash tables first using
balanced binary trees -- this would be way cool!

In other words, it might be cool to build everything from the bottom
up, e.g.:

1. Balanced binary tree
2. Hash Table
3. Graph (using hash table representation)

Discussion of common graph algorithms.

Traversal: TBD.

Search: Dijkstra's Algorithm.

* Appendix A: Helper Code

This appendix contains the ``helper code'' used in the book: 
